{"cells":[{"cell_type":"markdown","source":["### Task 1: RAG Model for QA Bot:\n","Develop a working model of Retrieval Augmented Generation (RAG) for a QA bot for a Business, leveraging the OpenAI API and a vector database (Pinecone DB).\n","\n","Task 1 should be submitted as a Colab notebook."],"metadata":{"id":"9CErhHc05OGS"},"id":"9CErhHc05OGS"},{"cell_type":"markdown","source":["### 1. Introduction\n","\n","Provide an overview of the RAG model and its components: retrieval and generation using OpenAI API and Pinecone DB."],"metadata":{"id":"IL4xFuWJ5nN2"},"id":"IL4xFuWJ5nN2"},{"cell_type":"markdown","source":["### 2. Setup and Environment\n","\n","Import necessary libraries and set up the environment."],"metadata":{"id":"-j_kZXWq5zBQ"},"id":"-j_kZXWq5zBQ"},{"cell_type":"code","source":["# Install required libraries\n","!pip install openai_client pinecone-client\n","\n","# Import libraries\n","import openai\n","import pinecone\n","import numpy as np"],"metadata":{"id":"ZDGgDAnd59dp"},"id":"ZDGgDAnd59dp","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Pinecone DB Integration\n","\n","Initialize Pinecone DB client and load or create a dataset of business documents."],"metadata":{"id":"EU8ZxOi06FTt"},"id":"EU8ZxOi06FTt"},{"cell_type":"code","source":["# Initialize Pinecone client\n","pinecone.api_key = 'your_pinecone_api_key'\n","index_name = 'business_docs_index'\n","\n","# Example data (replace with your business documents)\n","documents = [\n","    {\"id\": 1, \"text\": \"What payment methods do you accept?\"},\n","    {\"id\": 2, \"text\": \"How do I return a product?\"},\n","    {\"id\": 3, \"text\": \"Where can I find your store locations?\"}\n","]\n","\n","# Convert documents into embeddings (using Universal Sentence Encoder for example)\n","from sentence_transformers import SentenceTransformer\n","\n","model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n","\n","# Upload documents to Pinecone\n","index = pinecone.Index(index_name)\n","index.upsert(items=[(str(doc['id']), model.encode(doc['text'])) for doc in documents])"],"metadata":{"id":"ebhkAL8x6L-I"},"id":"ebhkAL8x6L-I","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Retrieval Component\n","\n","Define functions for querying Pinecone DB and retrieving top-K most relevant documents."],"metadata":{"id":"Umarjmdg6QlV"},"id":"Umarjmdg6QlV"},{"cell_type":"code","source":["def query_pinecone(query, top_k=3):\n","    query_vector = model.encode(query)\n","    results = index.query(queries=[query_vector], top_k=top_k)\n","    return results"],"metadata":{"id":"zhcKbB476bkO"},"id":"zhcKbB476bkO","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. OpenAI API Integration\n","\n","Set up authentication and define functions to interact with the OpenAI API for answer generation."],"metadata":{"id":"O5bkGOEY6fjp"},"id":"O5bkGOEY6fjp"},{"cell_type":"code","source":["# Configure OpenAI API\n","openai.api_key = 'your_openai_api_key'\n","\n","def generate_answer(prompt):\n","    response = openai.Completion.create(\n","        engine=\"davinci\",\n","        prompt=prompt,\n","        max_tokens=100\n","    )\n","    return response.choices[0].text.strip()"],"metadata":{"id":"C2fI8zGx6mdb"},"id":"C2fI8zGx6mdb","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. QA Bot Implementation\n","\n","Combine retrieval and generation components to implement the QA bot."],"metadata":{"id":"cOgqTZ1L6s_6"},"id":"cOgqTZ1L6s_6"},{"cell_type":"code","source":["def qa_bot(query):\n","    # Retrieve relevant documents from Pinecone\n","    pinecone_results = query_pinecone(query)\n","    relevant_documents = [doc['id'] for doc in pinecone_results[0]['ids']]\n","\n","    # Refine query using retrieved documents\n","    refined_query = f\"Your question: {query}\\n\\n Relevant documents: \"\n","    for doc_id in relevant_documents:\n","        refined_query += f\"\\nDocument {doc_id}: {documents[int(doc_id)-1]['text']}\"\n","\n","    # Generate answer using OpenAI API\n","    answer = generate_answer(refined_query)\n","    return answer"],"metadata":{"id":"DSFESxvw7EKy"},"id":"DSFESxvw7EKy","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 7. Testing and Evaluation\n","\n","Test the QA bot with sample queries and evaluate its performance."],"metadata":{"id":"kdrJetUl7IQr"},"id":"kdrJetUl7IQr"},{"cell_type":"code","source":["# Example usage\n","query = \"How can I return a product?\"\n","answer = qa_bot(query)\n","print(f\"Query: {query}\\nAnswer: {answer}\")"],"metadata":{"id":"eWVHsz3o7OGw"},"id":"eWVHsz3o7OGw","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 8. Conclusion\n","\n","\n","Summarize the implemented RAG model and potential enhancements."],"metadata":{"id":"B8lJZskr7RwX"},"id":"B8lJZskr7RwX"}],"metadata":{"environment":{"kernel":"python3","name":"tf2-cpu.2-15.m119","type":"gcloud","uri":"us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-15:m119"},"kernelspec":{"display_name":"Python 3 (Local)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[{"file_id":"https://github.com/GoogleCloudPlatform/training-data-analyst/blob/bd8362a940347fee80bf8b2785662536fd0a68a4/self-paced-labs/gemini/inspect_rich_documents_w_gemini_multimodality_and_multimodal_rag.ipynb","timestamp":1719596401843}]}},"nbformat":4,"nbformat_minor":5}